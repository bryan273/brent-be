{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from pickle/train_documents.pkl\n"
     ]
    }
   ],
   "source": [
    "from data_preparator import DataPreparator\n",
    "test = DataPreparator.load_from_pickle('pickle/train_documents.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Initialize an empty dictionary to store the mappings\n",
    "file_mapping = {}\n",
    "\n",
    "# Walk through the folder structure\n",
    "for root, dirs, files in os.walk(\"collections\"):\n",
    "    for file in files:\n",
    "        # Check if the file has a .txt extension\n",
    "        if file.endswith(\".txt\"):\n",
    "            # Get the full path of the file\n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            # Extract the file name (without extension)\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            \n",
    "            # Add the mapping to the dictionary\n",
    "            file_mapping[file_name] = file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\bryan/.cache\\torch\\sentence_transformers\\m-aliabbas1_tiny_bert_29_medicare_intents. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\bryan/.cache\\torch\\sentence_transformers\\m-aliabbas1_tiny_bert_29_medicare_intents were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from retrieval import Retrieval\n",
    "from letor import LETOR\n",
    "import re\n",
    "\n",
    "ranker_path = \"lgbr_base.txt\"\n",
    "letor = LETOR(ranker_path)\n",
    "retrieval = Retrieval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pipeline_letor(query, k=100):\n",
    "\n",
    "    clean_text = \" \".join(re.findall(r\"\\w+\", query))\n",
    "    terms = retrieval.data_preparator.preprocess_text(clean_text).split(' ')\n",
    "\n",
    "    doc_paths, _ = retrieval.retrieve_documents(terms)\n",
    "    doc_ids = [doc_path.split('\\\\')[-1][:-4] for doc_path in doc_paths]\n",
    "    dataset = retrieval.data_preparator.prepare_testing_dataset(terms, doc_paths)\n",
    "\n",
    "    # melakukan preparation data test dan prediksi \n",
    "    X = letor.ranker.prepare_data_test(dataset)\n",
    "    pred = letor.ranker.predict_ranker(X) +  X[:,-1]/100\n",
    "    doc_pred_pairs = list(zip(doc_ids, pred))\n",
    "    sorted_pairs = sorted(doc_pred_pairs, key=lambda x: x[1], reverse=True)\n",
    "    top_k_doc_ids_letor = [pair[0] for pair in sorted_pairs]\n",
    "    top_k_doc_ids_bsbi = doc_ids\n",
    "\n",
    "    intersection = [x for x in top_k_doc_ids_letor if x in top_k_doc_ids_bsbi]\n",
    "    intersection = intersection + [x for x in top_k_doc_ids_letor if x not in intersection]\n",
    "\n",
    "    return intersection[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = main_pipeline_letor(\"cardiovascular disease\", \n",
    "                                                k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5468651', '5641487', '50143', '821954', '52209', '60427', '17061', '835748', '47209', '4747270', '11288', '2686161', '990', '16366', '477242', '24148', '17063', '7065630', '28660', '3443459', '49378', '16844', '22726', '2884753', '169434', '60609', '4095426', '2166', '2167', '54999', '13060', '6680388', '841697', '18221', '12957', '7379223', '5410023', '13162', '64179', '12965', '5418192', '5394632', '2155841', '5302845', '1267712', '1793583', '15550', '4658404', '5282880', '3519021']\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep apnea is known to contribute to the development of cardiovascular disease and pulmonary hypertension. It happens because the disease increases the risk of hypertension, pulmonary vascular disease, ischemic heart disease, stroke, congestive heart failure and arrhythmias.\n"
     ]
    }
   ],
   "source": [
    "# Open the file for reading\n",
    "with open(file_mapping['5468651'], \"r\") as file:\n",
    "    # Read and print the content\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object saved as pickle/mapping_doc.pkl\n"
     ]
    }
   ],
   "source": [
    "from data_preparator import DataPreparator\n",
    "DataPreparator.save_to_pickle(file_mapping, \"pickle/mapping_doc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from pickle/mapping_doc.pkl\n"
     ]
    }
   ],
   "source": [
    "mapping = DataPreparator.load_from_pickle(\"pickle/mapping_doc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'collections\\\\9\\\\8826292.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "file_path = 'stopwords.txt'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "with open(file_path, 'w') as file:\n",
    "    for word in stop_words:\n",
    "        file.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(line.strip() for line in open('stopwords.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\bryan/.cache\\torch\\sentence_transformers\\m-aliabbas1_tiny_bert_29_medicare_intents. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\bryan/.cache\\torch\\sentence_transformers\\m-aliabbas1_tiny_bert_29_medicare_intents were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from pickle\\test_data.pkl\n"
     ]
    }
   ],
   "source": [
    "from letor import LETOR\n",
    "import pandas as pd\n",
    "ranker_path = \"lgbr_base.txt\"\n",
    "model_path = \"lsi_base.model\"\n",
    "data_path = r'pickle\\test_data.pkl'\n",
    "qrel_path = r\"qrels-folder\\test_qrels.txt\"\n",
    "\n",
    "letor = LETOR(ranker_path, data_path)\n",
    "qrels = letor.data_preparator.read_qrels_test(qrel_path)\n",
    "\n",
    "data = letor.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\bryan/.cache\\torch\\sentence_transformers\\m-aliabbas1_tiny_bert_29_medicare_intents. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\bryan/.cache\\torch\\sentence_transformers\\m-aliabbas1_tiny_bert_29_medicare_intents were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from pickle\\test_data.pkl\n"
     ]
    }
   ],
   "source": [
    "from letor import LETOR\n",
    "import pandas as pd\n",
    "ranker_path = \"lgbr_base.txt\"\n",
    "model_path = \"lsi_base.model\"\n",
    "data_path = r'pickle\\test_data.pkl'\n",
    "qrel_path = r\"qrels-folder\\test_qrels.txt\"\n",
    "\n",
    "letor = LETOR(ranker_path, model_path, data_path)\n",
    "qrels = letor.data_preparator.read_qrels_test(qrel_path)\n",
    "\n",
    "data = letor.data\n",
    "\n",
    "ndcgs_letor = []\n",
    "ndcgs_bsbi = []\n",
    "\n",
    "columns = ['query_id', 'doc_id', 'score', 'relevance']\n",
    "df_letor = pd.DataFrame(columns=columns)\n",
    "df_bsbi = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# iterate untuk setiap query\n",
    "for qid in tqdm(qrels):\n",
    "    dataset, doc_ids, raw_scores = data[qid]\n",
    "    qrel = qrels[qid]\n",
    "    k = 25\n",
    "\n",
    "    # melakukan preparation data test dan prediksi \n",
    "    X = letor.ranker.prepare_data_test(dataset)\n",
    "    pred = letor.ranker.predict_ranker(X)\n",
    "    \n",
    "    # untuk mendapatkan top k dokumen\n",
    "    doc_pred_pairs = list(zip(doc_ids, pred))\n",
    "    sorted_pairs = sorted(doc_pred_pairs, key=lambda x: x[1], reverse=True)\n",
    "    top_k_doc_ids_letor = [pair[0] for pair in sorted_pairs[:k]]\n",
    "    top_k_doc_ids_letor = ['D'+ doc for doc in top_k_doc_ids_letor]\n",
    "\n",
    "    top_k_doc_ids_bsbi = doc_ids[:k]\n",
    "    top_k_doc_ids_bsbi = ['D'+ doc for doc in top_k_doc_ids_bsbi]\n",
    "\n",
    "    # mendapatkan ranking dari top k doc yang di sort\n",
    "    ranking_letor = [qrel[did] for did in top_k_doc_ids_letor]\n",
    "    ranking_bsbi = [qrel[did] for did in top_k_doc_ids_bsbi]\n",
    "    \n",
    "    # Hasil nDCG untuk model \"letor\" dan model \"bsbi\" akan dihitung dan disimpan.\n",
    "    ndcg_score_letor = LETOR.ndcg(ranking_letor)\n",
    "    ndcg_score_bsbi = LETOR.ndcg(ranking_bsbi)\n",
    "\n",
    "    ndcgs_letor.append(ndcg_score_letor)\n",
    "    ndcgs_bsbi.append(ndcg_score_bsbi)\n",
    "    \n",
    "    # Create DataFrames for 'letor' and 'bsbi' scores in the current loop\n",
    "    df_letor_loop = pd.DataFrame({'query_id': [qid]*len(ranking_letor),\n",
    "                                'doc_id': top_k_doc_ids_letor,\n",
    "                                'score': [pair[1] for pair in sorted_pairs[:k]],\n",
    "                                'relevance': ranking_letor})\n",
    "    \n",
    "    df_bsbi_loop = pd.DataFrame({'query_id': [qid]*len(ranking_letor),\n",
    "                                'doc_id': top_k_doc_ids_bsbi,\n",
    "                                'score': raw_scores[:k],\n",
    "                                'relevance': ranking_bsbi})\n",
    "\n",
    "    # Concatenate the DataFrames to the main DataFrames\n",
    "    df_letor = pd.concat([df_letor, df_letor_loop], ignore_index=True)\n",
    "    df_bsbi = pd.concat([df_bsbi, df_bsbi_loop], ignore_index=True)\n",
    "\n",
    "print(\"Mean NDCG Score for Letor:\", sum(ndcgs_letor) / len(ndcgs_letor))\n",
    "print(\"Mean NDCG Score for BSBI:\", sum(ndcgs_bsbi) / len(ndcgs_bsbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [03:56<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG Score for Letor: 0.4983136725250903\n",
      "Mean NDCG Score for BSBI: 0.6134689162548457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# iterate untuk setiap query\n",
    "for qid in tqdm(qrels):\n",
    "    dataset, doc_ids, raw_scores = data[qid]\n",
    "    qrel = qrels[qid]\n",
    "    k = 25\n",
    "\n",
    "    # melakukan preparation data test dan prediksi \n",
    "    X = letor.ranker.prepare_data_test(dataset)\n",
    "    pred = letor.ranker.predict_ranker(X)\n",
    "    \n",
    "    # untuk mendapatkan top k dokumen\n",
    "    doc_pred_pairs = list(zip(doc_ids, pred))\n",
    "    sorted_pairs = sorted(doc_pred_pairs, key=lambda x: x[1], reverse=True)\n",
    "    sorted_pairs = [('D'+doc, score) for doc, score in sorted_pairs]\n",
    "\n",
    "    top_k_doc_ids_bsbi = doc_ids[:k]\n",
    "    top_k_doc_ids_bsbi = ['D'+ doc for doc in top_k_doc_ids_bsbi]\n",
    "    \n",
    "    # mendapatkan ranking dari top k doc yang di sort\n",
    "    list_rel = []\n",
    "    curr_score = 0\n",
    "    rel = 0\n",
    "    for did,score in sorted_pairs:\n",
    "        if len(list_rel)==k+1:\n",
    "            break\n",
    "        if score != curr_score:\n",
    "            list_rel.append(rel)\n",
    "            rel = 0\n",
    "            curr_score = score\n",
    "            if qrel[did]: rel=1\n",
    "        else:\n",
    "            if not rel: rel=qrel[did]  \n",
    "\n",
    "    ranking_letor = list_rel[1:]\n",
    "    ranking_bsbi = [qrel[did] for did in top_k_doc_ids_bsbi]\n",
    "    \n",
    "    # Hasil nDCG untuk model \"letor\" dan model \"bsbi\" akan dihitung dan disimpan.\n",
    "    ndcg_score_letor = LETOR.ndcg(ranking_letor)\n",
    "    ndcg_score_bsbi = LETOR.ndcg(ranking_bsbi)\n",
    "\n",
    "    ndcgs_letor.append(ndcg_score_letor)\n",
    "    ndcgs_bsbi.append(ndcg_score_bsbi)\n",
    "\n",
    "print(\"Mean NDCG Score for Letor:\", sum(ndcgs_letor) / len(ndcgs_letor))\n",
    "print(\"Mean NDCG Score for BSBI:\", sum(ndcgs_bsbi) / len(ndcgs_bsbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_letor to a CSV file\n",
    "df_letor.to_csv('df_letor.csv', index=False)\n",
    "\n",
    "# Save df_bsbi to a CSV file\n",
    "df_bsbi.to_csv('df_bsbi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a62c838856e4c9b91e073de669ea6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b096fe97bfad414fac33b80453105fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05e466dc30f42bfaf47e0846a7b3523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/82.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2043673145e47e38316b4d09da351d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.91k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068cbbc161c94189aa55c14debd51b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/17.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff61077b0b849f99632ae3dba4b97f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a062afe3fda04b659b5b127d70a82009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28624028ba6647458f8ee277c2e6b947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b01ffa32acc4dff9b474e8bac1b6626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a45ea8fcc9648b5a666b23114afadce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\bryan/.cache\\torch\\sentence_transformers\\m-aliabbas1_tiny_bert_29_medicare_intents. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\bryan/.cache\\torch\\sentence_transformers\\m-aliabbas1_tiny_bert_29_medicare_intents were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_model = SentenceTransformer(\"m-aliabbas1/tiny_bert_29_medicare_intents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8485f2e870e4997900c74662633a4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "embeddings = sentence_model.encode([\"haloo nama gw bryan tjandra, lu siapa?\"], show_progress_bar=True)\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "normalized_embeddings = normalize(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_embeddings.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from pickle\\train_documents.pkl\n",
      "Object loaded from pickle\\train_queries.pkl\n",
      "Object loaded from pickle\\val_documents.pkl\n",
      "Object loaded from pickle\\val_queries.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\bryan/.cache\\torch\\sentence_transformers\\m-aliabbas1_tiny_bert_29_medicare_intents. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\bryan/.cache\\torch\\sentence_transformers\\m-aliabbas1_tiny_bert_29_medicare_intents were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from ranker import Ranker\n",
    "from data_preparator import DataPreparator\n",
    "\n",
    "train_doc_pkl = r'pickle\\train_documents.pkl'\n",
    "train_query_pkl = r'pickle\\train_queries.pkl'\n",
    "val_doc_pkl = r'pickle\\val_documents.pkl'\n",
    "val_query_pkl = r'pickle\\val_queries.pkl'\n",
    "\n",
    "# load file dari pickle\n",
    "train_documents = DataPreparator.load_from_pickle(train_doc_pkl)\n",
    "train_queries = DataPreparator.load_from_pickle(train_query_pkl)\n",
    "val_documents = DataPreparator.load_from_pickle(val_doc_pkl)\n",
    "val_queries = DataPreparator.load_from_pickle(val_query_pkl)\n",
    "\n",
    "# membuat model LSI dari dokumen train\n",
    "ranker = Ranker()\n",
    "# ranker.create_lsi_model(train_documents)\n",
    "\n",
    "# mempersiapkan train dataset dan validation dataset\n",
    "train_qrel_path = r\"qrels-folder\\train_qrels.txt\"\n",
    "val_qrel_path = r\"qrels-folder\\val_qrels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_group_qid_count = ranker.data_preparator.prepare_training_dataset(train_qrel_path, train_queries, train_documents)\n",
    "val_dataset, val_group_qid_count = ranker.data_preparator.prepare_training_dataset(val_qrel_path, val_queries, val_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from tqdm import tqdm\n",
    "\n",
    "def features(query, doc, is_batch=False):\n",
    "    \"\"\"\n",
    "    Fungsi untuk membangun fitur untuk training model\n",
    "    X: fitur, Y: target\n",
    "    \"\"\"\n",
    "\n",
    "    if not is_batch:\n",
    "        # Hasil BERT\n",
    "        v_q = normalize(sentence_model.encode([query])).flatten().tolist()\n",
    "        v_d = normalize(sentence_model.encode([doc])).flatten().tolist()\n",
    "        \n",
    "        # Fitur tambahan cosine dan jaccard\n",
    "        cosine_dist = cosine(v_q, v_d)\n",
    "        jaccard = len(set(query.split()) & set(doc.split())) / len(set(query.split()) | set(doc.split()))\n",
    "        return v_q + v_d + [jaccard, cosine_dist]\n",
    "    else:\n",
    "        # Handle batch queries and documents\n",
    "        # print(query, doc)\n",
    "        batch_features = []\n",
    "        v_q = normalize(sentence_model.encode(query)).tolist()\n",
    "        v_d = normalize(sentence_model.encode(doc)).tolist()\n",
    "            \n",
    "        for i, (query, doc) in enumerate(zip(query, doc)):\n",
    "\n",
    "            cosine_dist = cosine(v_q[i], v_d[i])\n",
    "            jaccard = len(set(query.split()) & set(doc.split())) / len(set(query.split()) | set(doc.split()))\n",
    "            \n",
    "            batch_features.append(v_q[i] + v_d[i] + [jaccard, cosine_dist])\n",
    "        return batch_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285600/285600 [07:59<00:00, 595.41it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256  # Specify the batch size\n",
    "is_batch = batch_size > 1\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "batch_queries = []\n",
    "batch_docs = []\n",
    "\n",
    "for data in tqdm(train_dataset):\n",
    "    query, doc, rel = data\n",
    "    query = ' '.join(query)\n",
    "    doc = ' '.join(doc)\n",
    "    \n",
    "    batch_queries.append(query)\n",
    "    batch_docs.append(doc)\n",
    "    Y.append(rel)\n",
    "    \n",
    "    if len(batch_queries) == batch_size:\n",
    "        if is_batch:\n",
    "            X.extend(features(batch_queries, batch_docs, is_batch))\n",
    "        else:\n",
    "            X.append(features(batch_queries, batch_docs, is_batch))\n",
    "        \n",
    "        # Clear the batch lists\n",
    "        batch_queries = []\n",
    "        batch_docs = []\n",
    "\n",
    "# Process any remaining data in the last batch\n",
    "if batch_queries:\n",
    "    if is_batch:\n",
    "        X.extend(features(batch_queries, batch_docs, is_batch))\n",
    "    else:\n",
    "        X.append(features(batch_queries, batch_docs, is_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285600, 258)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285600,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.array(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# membuat representasi fitur X dan label Y\n",
    "X_train, Y_train = ranker.prepare_data_train(train_dataset)\n",
    "X_val, Y_val = ranker.prepare_data_train(val_dataset)\n",
    "\n",
    "# melatih model ranker\n",
    "ranker.fit_ranker(X_train, Y_train, train_group_qid_count,\n",
    "                    X_val, Y_val, val_group_qid_count)\n",
    "\n",
    "# Setelah melakukan fit pada model\n",
    "best_score = ranker.ranker.best_score_['val'] \n",
    "print(f\"Best NDCG score on validation set: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
