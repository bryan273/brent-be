{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from pickle/train_documents.pkl\n"
     ]
    }
   ],
   "source": [
    "from data_preparator import DataPreparator\n",
    "test = DataPreparator.load_from_pickle('pickle/train_documents.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not exists at pickle\\test_data.pkl\n"
     ]
    }
   ],
   "source": [
    "from letor import LETOR\n",
    "\n",
    "ranker_path = \"lgbr_base.txt\"\n",
    "model_path = \"lsi_base.model\"\n",
    "data_path = r'pickle\\test_data.pkl'\n",
    "qrel_path = r\"qrels-folder\\test_qrels.txt\"\n",
    "letor = LETOR(ranker_path, model_path, data_path)\n",
    "qrels = letor.data_preparator.read_qrels_test(qrel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from pickle\\test_data.pkl\n"
     ]
    }
   ],
   "source": [
    "from letor import LETOR\n",
    "import pandas as pd\n",
    "\n",
    "ranker_path = \"lgbr_base.txt\"\n",
    "model_path = \"lsi_base.model\"\n",
    "data_path = r'pickle\\test_data.pkl'\n",
    "qrel_path = r\"qrels-folder\\test_qrels.txt\"\n",
    "\n",
    "letor = LETOR(ranker_path, model_path, data_path)\n",
    "qrels = letor.data_preparator.read_qrels_test(qrel_path)\n",
    "\n",
    "data = letor.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcgs_letor = []\n",
    "ndcgs_bsbi = []\n",
    "\n",
    "columns = ['query_id', 'doc_id', 'score', 'relevance']\n",
    "df_letor = pd.DataFrame(columns=columns)\n",
    "df_bsbi = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/700 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\spatial\\distance.py:636: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "C:\\Users\\bryan\\AppData\\Local\\Temp\\ipykernel_26612\\2218446069.py:44: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_letor = pd.concat([df_letor, df_letor_loop], ignore_index=True)\n",
      "C:\\Users\\bryan\\AppData\\Local\\Temp\\ipykernel_26612\\2218446069.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_bsbi = pd.concat([df_bsbi, df_bsbi_loop], ignore_index=True)\n",
      "100%|██████████| 700/700 [00:33<00:00, 20.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG Score for Letor: 0.45223863030279443\n",
      "Mean NDCG Score for BSBI: 0.6134689162548457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# iterate untuk setiap query\n",
    "for qid in tqdm(qrels):\n",
    "    dataset, doc_ids, raw_scores = data[qid]\n",
    "    qrel = qrels[qid]\n",
    "    k = 25\n",
    "\n",
    "    # melakukan preparation data test dan prediksi \n",
    "    X = letor.ranker.prepare_data_test(dataset)\n",
    "    pred = letor.ranker.predict_ranker(X)\n",
    "    \n",
    "    # untuk mendapatkan top k dokumen\n",
    "    doc_pred_pairs = list(zip(doc_ids, pred))\n",
    "    sorted_pairs = sorted(doc_pred_pairs, key=lambda x: x[1], reverse=True)\n",
    "    top_k_doc_ids_letor = [pair[0] for pair in sorted_pairs[:k]]\n",
    "    top_k_doc_ids_letor = ['D'+ doc for doc in top_k_doc_ids_letor]\n",
    "\n",
    "    top_k_doc_ids_bsbi = doc_ids[:k]\n",
    "    top_k_doc_ids_bsbi = ['D'+ doc for doc in top_k_doc_ids_bsbi]\n",
    "\n",
    "    # mendapatkan ranking dari top k doc yang di sort\n",
    "    ranking_letor = [qrel[did] for did in top_k_doc_ids_letor]\n",
    "    ranking_bsbi = [qrel[did] for did in top_k_doc_ids_bsbi]\n",
    "    \n",
    "    # Hasil nDCG untuk model \"letor\" dan model \"bsbi\" akan dihitung dan disimpan.\n",
    "    ndcg_score_letor = LETOR.ndcg(ranking_letor)\n",
    "    ndcg_score_bsbi = LETOR.ndcg(ranking_bsbi)\n",
    "\n",
    "    ndcgs_letor.append(ndcg_score_letor)\n",
    "    ndcgs_bsbi.append(ndcg_score_bsbi)\n",
    "    \n",
    "    # Create DataFrames for 'letor' and 'bsbi' scores in the current loop\n",
    "    df_letor_loop = pd.DataFrame({'query_id': [qid]*len(ranking_letor),\n",
    "                                'doc_id': top_k_doc_ids_letor,\n",
    "                                'score': [pair[1] for pair in sorted_pairs[:k]],\n",
    "                                'relevance': ranking_letor})\n",
    "    \n",
    "    df_bsbi_loop = pd.DataFrame({'query_id': [qid]*len(ranking_letor),\n",
    "                                'doc_id': top_k_doc_ids_bsbi,\n",
    "                                'score': raw_scores[:k],\n",
    "                                'relevance': ranking_bsbi})\n",
    "\n",
    "    # Concatenate the DataFrames to the main DataFrames\n",
    "    df_letor = pd.concat([df_letor, df_letor_loop], ignore_index=True)\n",
    "    df_bsbi = pd.concat([df_bsbi, df_bsbi_loop], ignore_index=True)\n",
    "\n",
    "print(\"Mean NDCG Score for Letor:\", sum(ndcgs_letor) / len(ndcgs_letor))\n",
    "print(\"Mean NDCG Score for BSBI:\", sum(ndcgs_bsbi) / len(ndcgs_bsbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_letor to a CSV file\n",
    "df_letor.to_csv('df_letor.csv', index=False)\n",
    "\n",
    "# Save df_bsbi to a CSV file\n",
    "df_bsbi.to_csv('df_bsbi.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
