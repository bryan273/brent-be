Germanyâ€™s defeat in 1918 meant the end of the German Empire. The Treaty of Versailles, the peace settlement negotiated by the victors (Britain, France, and the United States) in 1919, imposed punitive conditions on Germany, including the loss of territory, financial reparations, and a diminished military. These conditions set the stage for World War II.